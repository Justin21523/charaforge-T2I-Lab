# api/routers/safety.py - Safety endpoints implementation
from fastapi import APIRouter, HTTPException, UploadFile, File
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional
from pathlib import Path
from PIL import Image
import io

from core.t2i.safety import SafetyChecker

router = APIRouter()
safety_checker = SafetyChecker()


class NSFWCheckResponse(BaseModel):
    is_nsfw: bool
    confidence: float
    categories: Dict[str, float]
    content_hash: str


class PromptFilterRequest(BaseModel):
    prompt: str = Field(..., min_length=1, max_length=2000)
    strict_mode: bool = Field(default=False)


class PromptFilterResponse(BaseModel):
    original_prompt: str
    filtered_prompt: str
    blocked_terms: List[str]
    is_safe: bool


class WatermarkRequest(BaseModel):
    image_path: str = Field(..., description="Path to image file")
    watermark_text: str = Field(default="Generated by CharaForge")
    opacity: float = Field(default=0.1, ge=0.0, le=1.0)
    position: str = Field(default="bottom-right")


@router.post("/nsfw_check", response_model=NSFWCheckResponse)
async def check_nsfw_content(file: UploadFile = File(...)):
    """Check uploaded image for NSFW content"""

    # Validate file type
    if not file.content_type or not file.content_type.startswith("image/"):
        raise HTTPException(status_code=400, detail="File must be an image")

    try:
        # Load image
        image_data = await file.read()
        image = Image.open(io.BytesIO(image_data)).convert("RGB")

        # Run NSFW detection
        is_nsfw, scores = safety_checker.check_nsfw(image)
        content_hash = safety_checker.get_content_hash(image)

        # Get highest confidence category
        max_category = max(scores.items(), key=lambda x: x[1])
        confidence = max_category[1]

        return NSFWCheckResponse(
            is_nsfw=is_nsfw,
            confidence=confidence,
            categories=scores,
            content_hash=content_hash,
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"NSFW check failed: {str(e)}")


@router.post("/filter_prompt", response_model=PromptFilterResponse)
async def filter_prompt(request: PromptFilterRequest):
    """Filter inappropriate terms from text prompt"""

    try:
        filtered_prompt, blocked_terms = safety_checker.filter_prompt(request.prompt)

        is_safe = len(blocked_terms) == 0

        return PromptFilterResponse(
            original_prompt=request.prompt,
            filtered_prompt=filtered_prompt,
            blocked_terms=blocked_terms,
            is_safe=is_safe,
        )

    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"Prompt filtering failed: {str(e)}"
        )


@router.post("/analyze_content")
async def analyze_content_safety(
    file: UploadFile = File(...), prompt: str = "", strict_mode: bool = False
):
    """Comprehensive content safety analysis"""

    try:
        # Load image
        image_data = await file.read()
        image = Image.open(io.BytesIO(image_data)).convert("RGB")

        # Run comprehensive analysis
        analysis = safety_checker.analyze_content_safety(image, prompt)

        # Apply strict mode if requested
        if strict_mode:
            # Lower thresholds for strict mode
            nsfw_threshold = 0.3
            if analysis["nsfw_scores"].get("nsfw", 0) > nsfw_threshold:
                analysis["is_safe"] = False
                analysis["issues"].append("Content flagged in strict mode")

        return analysis

    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"Content analysis failed: {str(e)}"
        )


@router.post("/watermark")
async def add_watermark(request: WatermarkRequest):
    """Add watermark to image"""

    try:
        from core.t2i.watermark import WatermarkManager

        # Load image
        image_path = Path(request.image_path)
        if not image_path.exists():
            raise HTTPException(status_code=404, detail="Image not found")

        image = Image.open(image_path)

        # Add watermark
        watermark_manager = WatermarkManager()
        watermarked_image = watermark_manager.add_text_watermark(
            image,
            text=request.watermark_text,
            opacity=request.opacity,
            position=request.position,
        )

        # Save watermarked image
        output_path = image_path.parent / f"watermarked_{image_path.name}"
        watermarked_image.save(output_path)

        return {
            "message": "Watermark added successfully",
            "original_path": str(image_path),
            "watermarked_path": str(output_path),
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Watermarking failed: {str(e)}")


@router.get("/config")
async def get_safety_config():
    """Get current safety configuration"""

    return {
        "nsfw_detection_enabled": True,
        "prompt_filtering_enabled": True,
        "default_nsfw_threshold": 0.5,
        "strict_mode_threshold": 0.3,
        "blocked_terms_categories": list(safety_checker.blocked_terms.keys()),
        "watermark_enabled": True,
    }
